{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0a8693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.impute import IterativeImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44d568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df):\n",
    "    \n",
    "    \n",
    "    #94% dont have alleys, might not be super important\n",
    "    df.Alley = df.Alley.fillna(\"None\")\n",
    "    \n",
    "    #Could also fill with 0 - doenst have garage\n",
    "    df.GarageYrBlt = df.GarageYrBlt.fillna(0)\n",
    "    \n",
    "    #get rid\n",
    "    df.MasVnrArea = df.MasVnrArea.fillna(0)\n",
    "    df.MasVnrType = df.MasVnrType.fillna(\"None\")\n",
    "    df.BsmtFinSF1 = df.BsmtFinSF1.fillna(0)\n",
    "    df.BsmtFinSF2 = df.BsmtFinSF2.fillna(0)\n",
    "    df.BsmtUnfSF = df.BsmtUnfSF.fillna(0)\n",
    "    df.TotalBsmtSF = df.TotalBsmtSF.fillna(0)\n",
    "    df.GarageCars = df.GarageCars.fillna(0)\n",
    "    df.GarageArea = df.GarageArea.fillna(0)\n",
    "    df.BsmtFullBath = df.BsmtFullBath.fillna(0)\n",
    "    df.BsmtHalfBath = df.BsmtHalfBath.fillna(0)\n",
    "    \n",
    "    \n",
    "    #Bunch of non-missing values\n",
    "    df.BsmtQual = df.BsmtQual.fillna(\"NA\")\n",
    "    df.BsmtCond = df.BsmtCond.fillna(\"NA\")\n",
    "    df.BsmtExposure = df.BsmtExposure.fillna(\"NA\")\n",
    "    df.BsmtFinType1 = df.BsmtFinType1.fillna(\"NA\")\n",
    "    df.BsmtFinType2 = df.BsmtFinType2.fillna(\"NA\")\n",
    "    df.FireplaceQu = df.FireplaceQu.fillna(\"NA\")\n",
    "    df.GarageType = df.GarageType.fillna(\"NA\")\n",
    "    df.GarageFinish = df.GarageFinish.fillna(\"NA\")\n",
    "    df.GarageQual = df.GarageQual.fillna(\"NA\")\n",
    "    df.GarageCond = df.GarageCond.fillna(\"NA\")\n",
    "    df.PoolQC = df.PoolQC.fillna(\"NA\")\n",
    "    df.Fence = df.Fence.fillna(\"NA\")\n",
    "    df.MiscFeature = df.MiscFeature.fillna(\"NA\")\n",
    "    \n",
    "    #missing 0.068% and no missing in test so bye\n",
    "    df.Electrical = df.Electrical.fillna(\"SBrkr\")\n",
    "    df.Functional = df.Functional.fillna(\"Typ\")\n",
    "    \n",
    "    df.MSSubClass = df.MSSubClass.apply(str)\n",
    "    df.YrSold = df.YrSold.astype(str)\n",
    "    df.MoSold = df.MoSold.astype(str)\n",
    "    df.KitchenQual = df.KitchenQual.fillna(\"TA\")\n",
    "    \n",
    "    df.Exterior1st = df.Exterior1st.fillna(df.Exterior1st.mode()[0])\n",
    "    df.Exterior2nd = df.Exterior2nd.fillna(df.Exterior2nd.mode()[0])\n",
    "    df.SaleType = df.SaleType.fillna(df.SaleType.mode()[0])\n",
    "    df.Utilities = df.Utilities.fillna(df.Utilities.mode()[0])\n",
    "    \n",
    "    df.MSZoning = df.MSZoning.fillna(df.MSZoning.mode()[0])\n",
    "    df.LotFrontage = df.groupby('Neighborhood')[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    return df\n",
    "\n",
    "\n",
    "def target_encoder(df, target, labels):\n",
    "    dic = df.groupby(target)[labels].mean().to_dict()\n",
    "    \n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d750470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "Y = train.SalePrice\n",
    "train_features = train.drop([\"SalePrice\", \"Id\"], axis = 1) \n",
    "test_features = test.drop([\"Id\"], axis = 1)\n",
    "\n",
    "features = pd.concat([train_features, test_features], axis = 0)\n",
    "\n",
    "features = fill_missing(features)\n",
    "\n",
    "quantitative = [f for f in features.columns if features.dtypes[f] != 'object']\n",
    "qualitative = [f for f in features.columns if features.dtypes[f] == 'object']\n",
    "\n",
    "features[\"Total_Bathrooms\"] = features.BsmtFullBath + 0.5 * features.BsmtHalfBath + features.FullBath + 0.5 * features.HalfBath\n",
    "features[\"Has_Pool\"] = features.PoolArea.apply(lambda x: 1 if x > 0 else 0)\n",
    "features[\"TotalSF\"] = features.TotalBsmtSF + features[\"1stFlrSF\"] + features[\"2ndFlrSF\"]\n",
    "features[\"Has2ndFlr\"] = features[\"2ndFlrSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "features[\"HasFirePlace\"] = features[\"Fireplaces\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "features[\"HasBsmt\"] = features[\"TotalBsmtSF\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "features[\"HasGarage\"] = features[\"GarageArea\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "features[\"TotalPorchSF\"] = features[\"WoodDeckSF\"] + features[\"OpenPorchSF\"] + features[\"EnclosedPorch\"] + features['3SsnPorch'] + features[\"ScreenPorch\"]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "neigh_dict = target_encoder(train, \"Neighborhood\", \"SalePrice\")\n",
    "features.Neighborhood = features.Neighborhood.map(neigh_dict)\n",
    "quantitative.append(\"Neighborhood\")\n",
    "qualitative.remove(\"Neighborhood\")\n",
    "\n",
    "for col in quantitative: \n",
    "    target = features[col].to_numpy().reshape(-1, 1)\n",
    "    target = scaler.fit_transform(target)\n",
    "    features[col] = target\n",
    "    \n",
    "#seriously dumbfuck dummy encoding\n",
    "for col in qualitative:\n",
    "    dums = pd.get_dummies(features[col], prefix = str(col), drop_first = False)\n",
    "    features = features.drop([col], axis = 1)\n",
    "    features = pd.concat([features, dums], axis = 1)    \n",
    "    \n",
    "Y = Y.to_numpy().reshape(-1, 1)\n",
    "Y = np.log1p(Y)\n",
    "\n",
    "\n",
    "X = features[:len(train)]\n",
    "X_test = features[len(train):]\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, Y, test_size = 0.05, random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1b7f196f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.578121\n",
       "1      -0.578121\n",
       "2       0.218723\n",
       "3       0.218723\n",
       "4       2.212966\n",
       "          ...   \n",
       "1454   -1.379425\n",
       "1455   -1.379425\n",
       "1456   -0.401435\n",
       "1457   -0.401435\n",
       "1458   -0.401435\n",
       "Name: Neighborhood, Length: 1459, dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9279892b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0b39baa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3897\n",
      "[LightGBM] [Info] Number of data points in the train set: 1387, number of used features: 213\n",
      "[LightGBM] [Warning] Find whitespaces in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 12.025817\n",
      "[500]\ttrain's rmse: 0.00592034\tdev's rmse: 0.105211\n",
      "[1000]\ttrain's rmse: 0.00109788\tdev's rmse: 0.10482\n",
      "[1500]\ttrain's rmse: 0.000372421\tdev's rmse: 0.104825\n",
      "[2000]\ttrain's rmse: 0.000159713\tdev's rmse: 0.104824\n",
      "[2500]\ttrain's rmse: 7.73984e-05\tdev's rmse: 0.10482\n",
      "[3000]\ttrain's rmse: 3.91487e-05\tdev's rmse: 0.104819\n",
      "[3500]\ttrain's rmse: 2.03742e-05\tdev's rmse: 0.104818\n",
      "[4000]\ttrain's rmse: 1.09107e-05\tdev's rmse: 0.104818\n",
      "[4500]\ttrain's rmse: 5.90051e-06\tdev's rmse: 0.104818\n",
      "[5000]\ttrain's rmse: 3.20812e-06\tdev's rmse: 0.104818\n"
     ]
    }
   ],
   "source": [
    "train_dataset = lgb.Dataset(X_train, label = y_train)\n",
    "dev_dataset = lgb.Dataset(X_dev, label = y_dev, reference = train_dataset)\n",
    "\n",
    "param = {'num_leaves': 30, \n",
    "         'learning_rate':0.1, \n",
    "         'max_depth':-1, \n",
    "         'min_data_in_leaf':20, \n",
    "         'objective':'regression',\n",
    "        }\n",
    "\n",
    "param['metric'] = 'rmse'\n",
    "\n",
    "num_round = 5000\n",
    "bst = lgb.train(param, train_dataset, num_round, \n",
    "                valid_sets = [train_dataset, dev_dataset], \n",
    "                valid_names = ['train', 'dev'],\n",
    "                verbose_eval = 500\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cea5e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(filename, predictions, ID):\n",
    "    \n",
    "    ID = ID.to_numpy()\n",
    "\n",
    "    new_df = pd.DataFrame({\"Id\": ID, \"SalePrice\":predictions}, index = [0] * len(ID))\n",
    "    \n",
    "    new_df.to_csv(filename + \".csv\", index = False)\n",
    "    \n",
    "ID = test.Id\n",
    "predictions = np.expm1(bst.predict(X_test))\n",
    "write_to_csv('sub', predictions, test.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93da91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24eeea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmslog(y, y_pred):\n",
    "    m = len(y)\n",
    "    mse = np.sum((np.log(y + 1) - np.log(y_pred + 1)) ** 2) / m\n",
    "    print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "afd21a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.244151309908396\n",
      "4.141858730295136\n"
     ]
    }
   ],
   "source": [
    "rmslog(np.expm1(y_train), np.expm1(bst.predict(X_train)))\n",
    "rmslog(np.expm1(y_dev), np.expm1(bst.predict(X_dev)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
